# FruitPunch AI Bootcamp Session 1: Linear Regression

The timeline of machine learning starts with Legendre and Gauss fitting equations to data. This age-old algorithm will help us explore the fundamental 
concepts of machine learning like overfitting, error, gradient descent, train/test sets, signal, and noise. Since we mostly learn by doing, you will be working 
on multiple challenges during most of this session. For some challenges, you will implement algorithms without any ML library, and for others, you will use scikit-learn.

- Challenge 1: Use [scikit-learn](https://scikit-learn.org/) to do linear regression on the [diabetes dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html?highlight=diabetes#sklearn.datasets.load_diabetes).
- Challenge 2: Aleatoric vs. Epistemic uncertainty.
- Challenge 3: Overfitting.
- Challenge 4: Implement linear regression using gradient descent.

The code for this challenge is provided in .ipynb .pdf and .py. If you cannot run the code on your computer you can use [Google Colab](https://colab.research.google.com/).
Simply select File>Upload Notebook and upload the .ipynb file.

This challenge is prepared by [Mehmet Alican Noyan](https://twitter.com/malicannoyan).
